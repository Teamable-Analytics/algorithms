import json
import os
from datetime import datetime
from os import path
from typing import List, Dict, Any
import git
from api.models.team_set import TeamSet


class SimulationCache:
    """
    This class is used to cache the results of a simulation, which is a List[TeamSet], where each element of the list is a different run.
    All TeamSets should have been generated by the same algorithm (with the same settings).
    It uses the cache_key to generate a file with the results of the simulation.
    """

    def __init__(self, cache_key: str) -> None:
        self.cache_key = cache_key
        self._data = None
        """
        Dict in the form of:
        {
            "metadata": Dict[str, Any],  # Contains at least "timestamp" and "commit_hash"
            "team_sets": List[TeamSet],
        }
        """

    def exists(self) -> bool:
        """
        Checks if the cache_key is in the cache.
        """
        return path.exists(self._get_file())

    def get_teams(self) -> List[TeamSet]:
        """
        Gets the simulation results from the cache.
        """
        self._load_data()

        return self._data["team_sets"]

    def get_metadata(self) -> Dict[str, Any]:
        """
        Gets the metadata associated with the simulation results from the cache.
        """
        self._load_data()

        return self._data["metadata"]

    def save(
        self, simulation_results: List[TeamSet], metadata: Dict[str, Any] = None
    ) -> None:
        """
        Puts the simulation results into the cache.
        Overwrites any existing cache with the same cache_key.
        """

        # Get metadata
        metadata = metadata or {}
        metadata["timestamp"] = datetime.now().isoformat()
        # Get latest commit hash. This is so that we can track which commit generated the cache and go back to the code that generated it if needed. Would then be accessible at https://github.com/Teamable-Analytics/algorithms/commit/<commit_hash>
        metadata["commit_hash"] = git.Repo(
            search_parent_directories=True
        ).head.object.hexsha

        # Get stripped down version of TeamSets
        # TODO: Once Seth's code is merged
        stripped_team_sets = []

        # Make dict that will be stored
        cache_dict = {"metadata": metadata, "team_sets": stripped_team_sets}

        # Write to json file
        with open(self._get_file(), "w+") as file:
            json.dump(cache_dict, file)

    def clear(self) -> None:
        """
        Clears the cache.
        """
        if self.exists():
            os.remove(self._get_file())

    def _get_file(self) -> str:
        """
        Gets the file associated with the cache_key.
        """

        # Get cache directory
        current_dir = path.dirname(__file__)
        cache_dir = path.abspath(path.join(current_dir, "..", "..", "run_cache"))

        # Create cache directory if it doesn't exist
        if not path.exists(cache_dir):
            os.makedirs(cache_dir)

        # Get file
        return path.join(cache_dir, self.cache_key + ".json")

    def _load_data(self) -> None:
        if self._data is None:
            if not self.exists():
                raise FileNotFoundError("Cache doesn't exist")

            # Load json data
            with open(self._get_file(), "r") as f:
                json_data = json.load(f)

            # Parse json data
            # TODO: Parse json_data using Seth's code
            self._data: Dict[str, Any] = {}
